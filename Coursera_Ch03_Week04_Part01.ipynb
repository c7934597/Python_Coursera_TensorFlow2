{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coursera_Ch03_Week04_Part01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c7934597/Python_Coursera_TensorFlow2/blob/master/Coursera_Ch03_Week04_Part01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwsuGQQY9OL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PRnDnCW-Z7qv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9315bdaa-4d55-43dc-821e-da411f3fe267"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'replied': 246, 'all': 5, 'forget': 87, 'just': 48, 'being': 254, 'able': 227, 'catchers': 146, 'soon': 53, 'cheeks': 208, 'through': 186, 'go': 200, 'colleen': 230, 'chaneys': 237, 'ground': 81, 'tore': 233, 'jig': 162, 'some': 212, 'nolans': 129, 'cried': 191, 'reel': 161, 'father': 74, 'young': 182, 'acres': 80, 'to': 13, 'under': 234, 'weeks': 30, 'might': 104, 'hall': 141, 'gave': 82, 'town': 66, 'them': 57, 'his': 16, 'around': 177, 'chanters': 259, 'big': 243, 'swore': 198, 'entangled': 261, 'they': 19, 'new': 37, 'ogradys': 131, 'him': 33, 'minute': 106, 'groups': 179, 'gray': 144, 'banished': 158, 'potatoes': 125, 'ned': 223, 'mcgilligan': 120, 'sweetheart': 222, 'fainted': 64, 'kerrigan': 207, 'steps': 38, 'she': 14, 'small': 217, 'athy': 67, 'creature': 190, 'round': 25, 'stretched': 231, 'squeezed': 256, 'declared': 214, 'learn': 174, 'old': 55, 'ten': 79, 'doing': 150, 'tea': 128, 'bacon': 127, 'sure': 101, 'further': 202, 'odaly': 111, 'drop': 218, 'out': 32, 'row': 206, 'jeremy': 69, 'for': 7, 'singing': 148, 'away': 40, 'piper': 252, 'near': 253, 'mccarthy': 184, 'then': 240, 'pipes': 257, 'got': 23, 'fall': 171, 'lashings': 121, 'youll': 90, 'red': 210, 'be': 100, 'we': 157, 'kicked': 248, 'leg': 62, 'youd': 167, 'gathered': 196, 'lanigans': 9, 'punch': 122, 'free': 102, 'water': 136, 'peggy': 119, 'brooks': 172, 'merry': 50, 'murther': 193, 'put': 61, 'strangled': 255, 'come': 88, 'went': 134, 'both': 107, 'accident': 180, 'daughter': 147, 'would': 170, 'nelly': 143, 'cakes': 126, 'of': 8, 'ill': 93, 'ach': 163, 'dublin': 59, 'terrible': 249, 'meelia': 192, 'invitation': 103, 'arrived': 117, 'had': 203, 'taras': 140, 'think': 168, 'courting': 132, 'ladies': 124, 'runctions': 241, 'danced': 58, 'wall': 45, 'sweet': 142, 'ructions': 99, 'powerful': 226, 'nonsense': 159, 'julia': 156, 'one': 68, 'satisfaction': 204, 'ask': 105, 'right': 185, 'relations': 43, 'learning': 36, 'twas': 239, 'table': 235, 'miss': 63, 'your': 95, 'once': 138, 'little': 112, 'rows': 98, 'from': 65, 'glisten': 97, 'her': 27, 'songs': 133, 'introduction': 247, 'hoops': 188, 'there': 28, 'girls': 17, 'three': 29, 'long': 39, 'by': 232, 'hed': 199, 'their': 56, 'bees': 108, 'call': 116, 'too': 219, 'ribbons': 260, 'bellows': 258, 'was': 34, 'listen': 92, 'eyes': 96, 'dolans': 130, 'that': 26, 'painted': 215, 'academy': 173, 'mchugh': 245, 'carmody': 197, 'took': 216, 'but': 91, 'casey': 251, 'boys': 24, 'hadnt': 72, 'midst': 205, 'with': 118, 'he': 21, 'me': 52, 'couples': 178, 'myself': 46, 'made': 76, 'room': 154, 'oh': 238, 'up': 31, 'cask': 109, 'judy': 110, 'terrance': 183, 'morgan': 224, 'were': 11, 'smashed': 236, 'happened': 181, 'didnt': 86, 'called': 194, 'battered': 71, 'and': 1, 'pound': 73, 'give': 115, 'in': 4, 'lads': 213, 'ceiling': 169, 'an': 60, 'twist': 160, 'as': 18, 'hullabaloo': 250, 'at': 12, 'lanigan': 70, 'saw': 228, 'whirligig': 155, 'if': 89, 'again': 22, 'end': 262, 'dancing': 49, 'make': 94, 'when': 44, 'same': 209, 'rat': 145, 'til': 20, 'how': 165, 'phelim': 244, 'rose': 211, 'grand': 83, 'party': 84, 'stepped': 15, 'harp': 137, 'lick': 242, 'nice': 47, 'poor': 189, 'ball': 10, 'kinds': 151, 'brothers': 195, 'farm': 78, 'suppose': 221, 'who': 85, 'polkas': 153, 'much': 220, 'tipped': 51, 'mad': 166, 'plenty': 135, 'nothing': 175, 'friends': 42, 'milliner': 113, 'died': 75, 'man': 77, 'a': 3, 'finnertys': 187, 'mavrone': 164, 'i': 6, 'no': 201, 'spent': 35, 'together': 149, 'wink': 114, 'hearty': 176, 'so': 225, 'time': 54, 'fair': 229, 'the': 2, 'wine': 123, 'nonsensical': 152, 'sounded': 139, 'left': 41}\n",
            "263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soPGVheskaQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJtwVB2NbOAP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "9c829a3d-ae8c-4d50-ec21-9d20d54415e2"
      },
      "source": [
        "print(tokenizer.word_index['in'])\n",
        "print(tokenizer.word_index['the'])\n",
        "print(tokenizer.word_index['town'])\n",
        "print(tokenizer.word_index['of'])\n",
        "print(tokenizer.word_index['athy'])\n",
        "print(tokenizer.word_index['one'])\n",
        "print(tokenizer.word_index['jeremy'])\n",
        "print(tokenizer.word_index['lanigan'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "2\n",
            "66\n",
            "8\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49Cv68JOakwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "78437476-4df5-4e37-ac2d-ae44263cda62"
      },
      "source": [
        "print(xs[6])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  4  2 66  8 67 68 69]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY-jwvfgbEF8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "ff0cabe2-541a-4e2f-f570-ba0162bff6cc"
      },
      "source": [
        "print(ys[6])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtzlUMYadhKt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "d1f9ba20-30a2-44c0-d080-d770556cefc0"
      },
      "source": [
        "print(xs[5])\n",
        "print(ys[5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  0  0  0  4  2 66  8 67 68]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4myRpB1c4Gg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "131334f9-751b-4f38-8ced-1d171cfbb497"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'replied': 246, 'all': 5, 'forget': 87, 'just': 48, 'being': 254, 'able': 227, 'catchers': 146, 'soon': 53, 'cheeks': 208, 'through': 186, 'go': 200, 'colleen': 230, 'chaneys': 237, 'ground': 81, 'tore': 233, 'jig': 162, 'some': 212, 'nolans': 129, 'cried': 191, 'reel': 161, 'father': 74, 'young': 182, 'acres': 80, 'to': 13, 'under': 234, 'weeks': 30, 'might': 104, 'hall': 141, 'gave': 82, 'town': 66, 'them': 57, 'his': 16, 'around': 177, 'chanters': 259, 'big': 243, 'swore': 198, 'entangled': 261, 'they': 19, 'new': 37, 'ogradys': 131, 'him': 33, 'minute': 106, 'groups': 179, 'gray': 144, 'banished': 158, 'potatoes': 125, 'ned': 223, 'mcgilligan': 120, 'sweetheart': 222, 'fainted': 64, 'kerrigan': 207, 'steps': 38, 'she': 14, 'small': 217, 'athy': 67, 'creature': 190, 'round': 25, 'stretched': 231, 'squeezed': 256, 'declared': 214, 'learn': 174, 'old': 55, 'ten': 79, 'doing': 150, 'tea': 128, 'bacon': 127, 'sure': 101, 'further': 202, 'odaly': 111, 'drop': 218, 'out': 32, 'row': 206, 'jeremy': 69, 'for': 7, 'singing': 148, 'away': 40, 'piper': 252, 'near': 253, 'mccarthy': 184, 'then': 240, 'pipes': 257, 'got': 23, 'fall': 171, 'lashings': 121, 'youll': 90, 'red': 210, 'be': 100, 'we': 157, 'kicked': 248, 'leg': 62, 'youd': 167, 'gathered': 196, 'lanigans': 9, 'punch': 122, 'free': 102, 'water': 136, 'peggy': 119, 'brooks': 172, 'merry': 50, 'murther': 193, 'put': 61, 'strangled': 255, 'come': 88, 'went': 134, 'both': 107, 'accident': 180, 'daughter': 147, 'would': 170, 'nelly': 143, 'cakes': 126, 'of': 8, 'ill': 93, 'ach': 163, 'dublin': 59, 'terrible': 249, 'meelia': 192, 'invitation': 103, 'arrived': 117, 'had': 203, 'taras': 140, 'think': 168, 'courting': 132, 'ladies': 124, 'runctions': 241, 'danced': 58, 'wall': 45, 'sweet': 142, 'ructions': 99, 'powerful': 226, 'nonsense': 159, 'julia': 156, 'one': 68, 'satisfaction': 204, 'ask': 105, 'right': 185, 'relations': 43, 'learning': 36, 'twas': 239, 'table': 235, 'miss': 63, 'your': 95, 'once': 138, 'little': 112, 'rows': 98, 'from': 65, 'glisten': 97, 'her': 27, 'songs': 133, 'introduction': 247, 'hoops': 188, 'there': 28, 'girls': 17, 'three': 29, 'long': 39, 'by': 232, 'hed': 199, 'their': 56, 'bees': 108, 'call': 116, 'too': 219, 'ribbons': 260, 'bellows': 258, 'was': 34, 'listen': 92, 'eyes': 96, 'dolans': 130, 'that': 26, 'painted': 215, 'academy': 173, 'mchugh': 245, 'carmody': 197, 'took': 216, 'but': 91, 'casey': 251, 'boys': 24, 'hadnt': 72, 'midst': 205, 'with': 118, 'he': 21, 'me': 52, 'couples': 178, 'myself': 46, 'made': 76, 'room': 154, 'oh': 238, 'up': 31, 'cask': 109, 'judy': 110, 'terrance': 183, 'morgan': 224, 'were': 11, 'smashed': 236, 'happened': 181, 'didnt': 86, 'called': 194, 'battered': 71, 'and': 1, 'pound': 73, 'give': 115, 'in': 4, 'lads': 213, 'ceiling': 169, 'an': 60, 'twist': 160, 'as': 18, 'hullabaloo': 250, 'at': 12, 'lanigan': 70, 'saw': 228, 'whirligig': 155, 'if': 89, 'again': 22, 'end': 262, 'dancing': 49, 'make': 94, 'when': 44, 'same': 209, 'rat': 145, 'til': 20, 'how': 165, 'phelim': 244, 'rose': 211, 'grand': 83, 'party': 84, 'stepped': 15, 'harp': 137, 'lick': 242, 'nice': 47, 'poor': 189, 'ball': 10, 'kinds': 151, 'brothers': 195, 'farm': 78, 'suppose': 221, 'who': 85, 'polkas': 153, 'much': 220, 'tipped': 51, 'mad': 166, 'plenty': 135, 'nothing': 175, 'friends': 42, 'milliner': 113, 'died': 75, 'man': 77, 'a': 3, 'finnertys': 187, 'mavrone': 164, 'i': 6, 'no': 201, 'spent': 35, 'together': 149, 'wink': 114, 'hearty': 176, 'so': 225, 'time': 54, 'fair': 229, 'the': 2, 'wine': 123, 'nonsensical': 152, 'sounded': 139, 'left': 41}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vH8Y59ajYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "de79204d-cf4e-42cb-db9a-0e0862428ce8"
      },
      "source": [
        "  model = Sequential()\n",
        "  model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "  model.add(Bidirectional(LSTM(20)))\n",
        "  model.add(Dense(total_words, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  history = model.fit(xs, ys, epochs=500, verbose=1)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0907 08:25:10.904189 140716559349632 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/initializers.py:119: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0907 08:25:10.931195 140716559349632 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0907 08:25:10.938455 140716559349632 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0907 08:25:10.941343 140716559349632 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0907 08:25:10.944185 140716559349632 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0907 08:25:11.646436 140716559349632 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "453/453 [==============================] - 2s 5ms/sample - loss: 5.5693 - acc: 0.0155\n",
            "Epoch 2/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 5.5486 - acc: 0.0640\n",
            "Epoch 3/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 5.5072 - acc: 0.0530\n",
            "Epoch 4/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 5.3909 - acc: 0.0508\n",
            "Epoch 5/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 5.1646 - acc: 0.0508\n",
            "Epoch 6/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 5.0733 - acc: 0.0508\n",
            "Epoch 7/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 5.0256 - acc: 0.0574\n",
            "Epoch 8/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.9925 - acc: 0.0706\n",
            "Epoch 9/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.9516 - acc: 0.0684\n",
            "Epoch 10/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.9074 - acc: 0.0684\n",
            "Epoch 11/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.8511 - acc: 0.0751\n",
            "Epoch 12/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.7925 - acc: 0.0773\n",
            "Epoch 13/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.7283 - acc: 0.0773\n",
            "Epoch 14/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.6639 - acc: 0.0795\n",
            "Epoch 15/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.6001 - acc: 0.0905\n",
            "Epoch 16/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.5323 - acc: 0.0883\n",
            "Epoch 17/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.4786 - acc: 0.1015\n",
            "Epoch 18/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.4250 - acc: 0.1082\n",
            "Epoch 19/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.3769 - acc: 0.1170\n",
            "Epoch 20/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.3351 - acc: 0.1236\n",
            "Epoch 21/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.2815 - acc: 0.1347\n",
            "Epoch 22/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.2354 - acc: 0.1457\n",
            "Epoch 23/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.1839 - acc: 0.1567\n",
            "Epoch 24/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.1374 - acc: 0.1545\n",
            "Epoch 25/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.0828 - acc: 0.1611\n",
            "Epoch 26/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 4.0453 - acc: 0.1634\n",
            "Epoch 27/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.9925 - acc: 0.1744\n",
            "Epoch 28/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.9411 - acc: 0.1700\n",
            "Epoch 29/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.8970 - acc: 0.1898\n",
            "Epoch 30/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.8499 - acc: 0.1766\n",
            "Epoch 31/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.8016 - acc: 0.1810\n",
            "Epoch 32/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.7713 - acc: 0.1854\n",
            "Epoch 33/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.7182 - acc: 0.1898\n",
            "Epoch 34/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.6808 - acc: 0.1810\n",
            "Epoch 35/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.6394 - acc: 0.1921\n",
            "Epoch 36/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.6034 - acc: 0.2031\n",
            "Epoch 37/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.5526 - acc: 0.2097\n",
            "Epoch 38/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.5219 - acc: 0.2274\n",
            "Epoch 39/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.4933 - acc: 0.2340\n",
            "Epoch 40/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.4785 - acc: 0.2318\n",
            "Epoch 41/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.4374 - acc: 0.2539\n",
            "Epoch 42/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.3862 - acc: 0.2561\n",
            "Epoch 43/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.3438 - acc: 0.2671\n",
            "Epoch 44/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.3078 - acc: 0.2781\n",
            "Epoch 45/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.2734 - acc: 0.2848\n",
            "Epoch 46/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.2349 - acc: 0.2781\n",
            "Epoch 47/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.2039 - acc: 0.2914\n",
            "Epoch 48/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.1711 - acc: 0.3113\n",
            "Epoch 49/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.1384 - acc: 0.3091\n",
            "Epoch 50/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.1030 - acc: 0.3311\n",
            "Epoch 51/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.0819 - acc: 0.3024\n",
            "Epoch 52/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.0498 - acc: 0.3245\n",
            "Epoch 53/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 3.0064 - acc: 0.3201\n",
            "Epoch 54/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.9794 - acc: 0.3488\n",
            "Epoch 55/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.9539 - acc: 0.3576\n",
            "Epoch 56/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.9281 - acc: 0.3598\n",
            "Epoch 57/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.9183 - acc: 0.3400\n",
            "Epoch 58/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.9097 - acc: 0.3400\n",
            "Epoch 59/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.8688 - acc: 0.3532\n",
            "Epoch 60/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.8439 - acc: 0.3642\n",
            "Epoch 61/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.8203 - acc: 0.3929\n",
            "Epoch 62/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.7879 - acc: 0.3841\n",
            "Epoch 63/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.7531 - acc: 0.4018\n",
            "Epoch 64/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.7124 - acc: 0.4283\n",
            "Epoch 65/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.6854 - acc: 0.4283\n",
            "Epoch 66/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.6713 - acc: 0.4283\n",
            "Epoch 67/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.6402 - acc: 0.4459\n",
            "Epoch 68/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.6227 - acc: 0.4547\n",
            "Epoch 69/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.6063 - acc: 0.4525\n",
            "Epoch 70/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.5750 - acc: 0.4768\n",
            "Epoch 71/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.5442 - acc: 0.4879\n",
            "Epoch 72/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.5247 - acc: 0.4857\n",
            "Epoch 73/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.4927 - acc: 0.5011\n",
            "Epoch 74/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.4799 - acc: 0.5121\n",
            "Epoch 75/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.4724 - acc: 0.5099\n",
            "Epoch 76/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.4389 - acc: 0.5188\n",
            "Epoch 77/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.4442 - acc: 0.5166\n",
            "Epoch 78/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.4028 - acc: 0.5453\n",
            "Epoch 79/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.3762 - acc: 0.5475\n",
            "Epoch 80/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.3700 - acc: 0.5497\n",
            "Epoch 81/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.3756 - acc: 0.5430\n",
            "Epoch 82/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.3154 - acc: 0.5651\n",
            "Epoch 83/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.2906 - acc: 0.5740\n",
            "Epoch 84/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.2574 - acc: 0.5762\n",
            "Epoch 85/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.2349 - acc: 0.5850\n",
            "Epoch 86/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.2073 - acc: 0.5916\n",
            "Epoch 87/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.1896 - acc: 0.6004\n",
            "Epoch 88/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.1636 - acc: 0.6071\n",
            "Epoch 89/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.1443 - acc: 0.6026\n",
            "Epoch 90/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.1280 - acc: 0.6115\n",
            "Epoch 91/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.1107 - acc: 0.6181\n",
            "Epoch 92/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.0913 - acc: 0.6247\n",
            "Epoch 93/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.0724 - acc: 0.6159\n",
            "Epoch 94/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.0567 - acc: 0.6336\n",
            "Epoch 95/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.0430 - acc: 0.6358\n",
            "Epoch 96/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.0207 - acc: 0.6512\n",
            "Epoch 97/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 2.0016 - acc: 0.6512\n",
            "Epoch 98/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.9846 - acc: 0.6512\n",
            "Epoch 99/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.9644 - acc: 0.6556\n",
            "Epoch 100/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.9602 - acc: 0.6600\n",
            "Epoch 101/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.9383 - acc: 0.6534\n",
            "Epoch 102/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.9185 - acc: 0.6534\n",
            "Epoch 103/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.8998 - acc: 0.6578\n",
            "Epoch 104/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.8797 - acc: 0.6711\n",
            "Epoch 105/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.8571 - acc: 0.6777\n",
            "Epoch 106/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.8377 - acc: 0.6799\n",
            "Epoch 107/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.8249 - acc: 0.6843\n",
            "Epoch 108/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.8075 - acc: 0.6865\n",
            "Epoch 109/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.7960 - acc: 0.6711\n",
            "Epoch 110/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.7771 - acc: 0.6667\n",
            "Epoch 111/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.7601 - acc: 0.6799\n",
            "Epoch 112/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.7388 - acc: 0.6843\n",
            "Epoch 113/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.7219 - acc: 0.6954\n",
            "Epoch 114/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.7054 - acc: 0.7064\n",
            "Epoch 115/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.6845 - acc: 0.7020\n",
            "Epoch 116/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.6711 - acc: 0.7108\n",
            "Epoch 117/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.6588 - acc: 0.7174\n",
            "Epoch 118/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.6380 - acc: 0.7241\n",
            "Epoch 119/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.6274 - acc: 0.7285\n",
            "Epoch 120/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.6199 - acc: 0.7351\n",
            "Epoch 121/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.5941 - acc: 0.7285\n",
            "Epoch 122/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.5800 - acc: 0.7351\n",
            "Epoch 123/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.5662 - acc: 0.7219\n",
            "Epoch 124/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.5738 - acc: 0.7263\n",
            "Epoch 125/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.5569 - acc: 0.7395\n",
            "Epoch 126/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.5776 - acc: 0.7307\n",
            "Epoch 127/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.5475 - acc: 0.7152\n",
            "Epoch 128/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.5249 - acc: 0.7373\n",
            "Epoch 129/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.5029 - acc: 0.7483\n",
            "Epoch 130/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.4801 - acc: 0.7572\n",
            "Epoch 131/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.4705 - acc: 0.7594\n",
            "Epoch 132/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.4526 - acc: 0.7660\n",
            "Epoch 133/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.4335 - acc: 0.7704\n",
            "Epoch 134/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.4241 - acc: 0.7748\n",
            "Epoch 135/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3998 - acc: 0.7704\n",
            "Epoch 136/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3847 - acc: 0.7770\n",
            "Epoch 137/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3706 - acc: 0.7859\n",
            "Epoch 138/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3625 - acc: 0.7881\n",
            "Epoch 139/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3469 - acc: 0.7837\n",
            "Epoch 140/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3365 - acc: 0.7925\n",
            "Epoch 141/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3457 - acc: 0.7837\n",
            "Epoch 142/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3439 - acc: 0.7770\n",
            "Epoch 143/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3204 - acc: 0.7881\n",
            "Epoch 144/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.3077 - acc: 0.7969\n",
            "Epoch 145/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.2775 - acc: 0.7991\n",
            "Epoch 146/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.2594 - acc: 0.8057\n",
            "Epoch 147/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.2438 - acc: 0.8079\n",
            "Epoch 148/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.2307 - acc: 0.8190\n",
            "Epoch 149/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.2316 - acc: 0.8146\n",
            "Epoch 150/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.2160 - acc: 0.8212\n",
            "Epoch 151/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1983 - acc: 0.8256\n",
            "Epoch 152/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1887 - acc: 0.8278\n",
            "Epoch 153/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1868 - acc: 0.8256\n",
            "Epoch 154/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.2420 - acc: 0.8079\n",
            "Epoch 155/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.2254 - acc: 0.8079\n",
            "Epoch 156/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1955 - acc: 0.8190\n",
            "Epoch 157/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1577 - acc: 0.8190\n",
            "Epoch 158/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1265 - acc: 0.8411\n",
            "Epoch 159/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.1063 - acc: 0.8411\n",
            "Epoch 160/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.0997 - acc: 0.8366\n",
            "Epoch 161/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.0875 - acc: 0.8455\n",
            "Epoch 162/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.0768 - acc: 0.8521\n",
            "Epoch 163/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.0610 - acc: 0.8521\n",
            "Epoch 164/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.0459 - acc: 0.8565\n",
            "Epoch 165/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.0342 - acc: 0.8587\n",
            "Epoch 166/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.0254 - acc: 0.8587\n",
            "Epoch 167/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.0135 - acc: 0.8587\n",
            "Epoch 168/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 1.0028 - acc: 0.8609\n",
            "Epoch 169/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9925 - acc: 0.8631\n",
            "Epoch 170/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9863 - acc: 0.8631\n",
            "Epoch 171/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9737 - acc: 0.8720\n",
            "Epoch 172/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9636 - acc: 0.8720\n",
            "Epoch 173/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9506 - acc: 0.8720\n",
            "Epoch 174/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9435 - acc: 0.8720\n",
            "Epoch 175/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9331 - acc: 0.8742\n",
            "Epoch 176/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9260 - acc: 0.8698\n",
            "Epoch 177/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9158 - acc: 0.8764\n",
            "Epoch 178/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.9069 - acc: 0.8786\n",
            "Epoch 179/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8951 - acc: 0.8764\n",
            "Epoch 180/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8897 - acc: 0.8852\n",
            "Epoch 181/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8810 - acc: 0.8830\n",
            "Epoch 182/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8689 - acc: 0.8918\n",
            "Epoch 183/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8603 - acc: 0.8940\n",
            "Epoch 184/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8522 - acc: 0.8940\n",
            "Epoch 185/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8437 - acc: 0.8852\n",
            "Epoch 186/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8386 - acc: 0.8896\n",
            "Epoch 187/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8294 - acc: 0.8940\n",
            "Epoch 188/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8308 - acc: 0.8962\n",
            "Epoch 189/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8235 - acc: 0.8918\n",
            "Epoch 190/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8147 - acc: 0.8896\n",
            "Epoch 191/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8042 - acc: 0.8940\n",
            "Epoch 192/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.8060 - acc: 0.8940\n",
            "Epoch 193/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7960 - acc: 0.8962\n",
            "Epoch 194/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7926 - acc: 0.8940\n",
            "Epoch 195/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7846 - acc: 0.8940\n",
            "Epoch 196/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7667 - acc: 0.8962\n",
            "Epoch 197/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7573 - acc: 0.9029\n",
            "Epoch 198/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7481 - acc: 0.9073\n",
            "Epoch 199/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7404 - acc: 0.9073\n",
            "Epoch 200/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7325 - acc: 0.9073\n",
            "Epoch 201/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7269 - acc: 0.9073\n",
            "Epoch 202/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7239 - acc: 0.9051\n",
            "Epoch 203/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7211 - acc: 0.9073\n",
            "Epoch 204/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7171 - acc: 0.9029\n",
            "Epoch 205/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.7100 - acc: 0.9051\n",
            "Epoch 206/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6974 - acc: 0.9117\n",
            "Epoch 207/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6885 - acc: 0.9095\n",
            "Epoch 208/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6797 - acc: 0.9205\n",
            "Epoch 209/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6754 - acc: 0.9161\n",
            "Epoch 210/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6647 - acc: 0.9183\n",
            "Epoch 211/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6579 - acc: 0.9161\n",
            "Epoch 212/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6489 - acc: 0.9249\n",
            "Epoch 213/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6481 - acc: 0.9249\n",
            "Epoch 214/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6402 - acc: 0.9205\n",
            "Epoch 215/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6342 - acc: 0.9272\n",
            "Epoch 216/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6266 - acc: 0.9249\n",
            "Epoch 217/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6219 - acc: 0.9227\n",
            "Epoch 218/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6198 - acc: 0.9227\n",
            "Epoch 219/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6192 - acc: 0.9227\n",
            "Epoch 220/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6121 - acc: 0.9205\n",
            "Epoch 221/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6113 - acc: 0.9272\n",
            "Epoch 222/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.6059 - acc: 0.9272\n",
            "Epoch 223/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5996 - acc: 0.9272\n",
            "Epoch 224/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5946 - acc: 0.9183\n",
            "Epoch 225/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5831 - acc: 0.9272\n",
            "Epoch 226/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5763 - acc: 0.9294\n",
            "Epoch 227/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5702 - acc: 0.9294\n",
            "Epoch 228/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5728 - acc: 0.9249\n",
            "Epoch 229/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5684 - acc: 0.9249\n",
            "Epoch 230/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5579 - acc: 0.9316\n",
            "Epoch 231/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5506 - acc: 0.9338\n",
            "Epoch 232/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5487 - acc: 0.9316\n",
            "Epoch 233/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5449 - acc: 0.9294\n",
            "Epoch 234/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5488 - acc: 0.9249\n",
            "Epoch 235/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5423 - acc: 0.9249\n",
            "Epoch 236/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5357 - acc: 0.9316\n",
            "Epoch 237/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5498 - acc: 0.9316\n",
            "Epoch 238/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5373 - acc: 0.9316\n",
            "Epoch 239/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5444 - acc: 0.9272\n",
            "Epoch 240/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5248 - acc: 0.9294\n",
            "Epoch 241/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5157 - acc: 0.9338\n",
            "Epoch 242/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5008 - acc: 0.9360\n",
            "Epoch 243/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4925 - acc: 0.9382\n",
            "Epoch 244/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4897 - acc: 0.9360\n",
            "Epoch 245/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4878 - acc: 0.9316\n",
            "Epoch 246/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4960 - acc: 0.9316\n",
            "Epoch 247/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5153 - acc: 0.9227\n",
            "Epoch 248/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5024 - acc: 0.9272\n",
            "Epoch 249/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.5044 - acc: 0.9316\n",
            "Epoch 250/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4930 - acc: 0.9294\n",
            "Epoch 251/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4907 - acc: 0.9360\n",
            "Epoch 252/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4903 - acc: 0.9249\n",
            "Epoch 253/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4625 - acc: 0.9338\n",
            "Epoch 254/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4610 - acc: 0.9382\n",
            "Epoch 255/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4559 - acc: 0.9338\n",
            "Epoch 256/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4478 - acc: 0.9382\n",
            "Epoch 257/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4419 - acc: 0.9382\n",
            "Epoch 258/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4338 - acc: 0.9360\n",
            "Epoch 259/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4256 - acc: 0.9404\n",
            "Epoch 260/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4200 - acc: 0.9382\n",
            "Epoch 261/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4152 - acc: 0.9404\n",
            "Epoch 262/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4107 - acc: 0.9382\n",
            "Epoch 263/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4066 - acc: 0.9382\n",
            "Epoch 264/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4034 - acc: 0.9360\n",
            "Epoch 265/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.4023 - acc: 0.9404\n",
            "Epoch 266/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3998 - acc: 0.9382\n",
            "Epoch 267/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3982 - acc: 0.9404\n",
            "Epoch 268/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3939 - acc: 0.9448\n",
            "Epoch 269/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3913 - acc: 0.9426\n",
            "Epoch 270/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3869 - acc: 0.9470\n",
            "Epoch 271/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3834 - acc: 0.9470\n",
            "Epoch 272/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3817 - acc: 0.9470\n",
            "Epoch 273/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3846 - acc: 0.9382\n",
            "Epoch 274/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3810 - acc: 0.9448\n",
            "Epoch 275/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3753 - acc: 0.9470\n",
            "Epoch 276/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3702 - acc: 0.9426\n",
            "Epoch 277/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3674 - acc: 0.9448\n",
            "Epoch 278/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3634 - acc: 0.9448\n",
            "Epoch 279/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3614 - acc: 0.9426\n",
            "Epoch 280/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3580 - acc: 0.9448\n",
            "Epoch 281/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3590 - acc: 0.9426\n",
            "Epoch 282/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3547 - acc: 0.9492\n",
            "Epoch 283/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3551 - acc: 0.9492\n",
            "Epoch 284/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3476 - acc: 0.9470\n",
            "Epoch 285/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3436 - acc: 0.9514\n",
            "Epoch 286/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3411 - acc: 0.9404\n",
            "Epoch 287/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3388 - acc: 0.9470\n",
            "Epoch 288/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3365 - acc: 0.9470\n",
            "Epoch 289/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3334 - acc: 0.9470\n",
            "Epoch 290/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3309 - acc: 0.9470\n",
            "Epoch 291/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3280 - acc: 0.9448\n",
            "Epoch 292/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3284 - acc: 0.9470\n",
            "Epoch 293/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3240 - acc: 0.9514\n",
            "Epoch 294/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3217 - acc: 0.9492\n",
            "Epoch 295/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3201 - acc: 0.9492\n",
            "Epoch 296/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3158 - acc: 0.9492\n",
            "Epoch 297/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3140 - acc: 0.9470\n",
            "Epoch 298/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3123 - acc: 0.9470\n",
            "Epoch 299/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3097 - acc: 0.9492\n",
            "Epoch 300/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3078 - acc: 0.9514\n",
            "Epoch 301/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3072 - acc: 0.9492\n",
            "Epoch 302/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3033 - acc: 0.9470\n",
            "Epoch 303/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3010 - acc: 0.9492\n",
            "Epoch 304/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2992 - acc: 0.9470\n",
            "Epoch 305/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2971 - acc: 0.9470\n",
            "Epoch 306/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3040 - acc: 0.9470\n",
            "Epoch 307/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3063 - acc: 0.9448\n",
            "Epoch 308/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3070 - acc: 0.9492\n",
            "Epoch 309/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3057 - acc: 0.9492\n",
            "Epoch 310/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3027 - acc: 0.9470\n",
            "Epoch 311/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3023 - acc: 0.9492\n",
            "Epoch 312/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.3028 - acc: 0.9492\n",
            "Epoch 313/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2946 - acc: 0.9470\n",
            "Epoch 314/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2888 - acc: 0.9514\n",
            "Epoch 315/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2942 - acc: 0.9470\n",
            "Epoch 316/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2930 - acc: 0.9448\n",
            "Epoch 317/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2876 - acc: 0.9470\n",
            "Epoch 318/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2814 - acc: 0.9492\n",
            "Epoch 319/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2868 - acc: 0.9448\n",
            "Epoch 320/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2752 - acc: 0.9470\n",
            "Epoch 321/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2724 - acc: 0.9514\n",
            "Epoch 322/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2671 - acc: 0.9492\n",
            "Epoch 323/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2652 - acc: 0.9492\n",
            "Epoch 324/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2626 - acc: 0.9492\n",
            "Epoch 325/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2609 - acc: 0.9492\n",
            "Epoch 326/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2592 - acc: 0.9492\n",
            "Epoch 327/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2573 - acc: 0.9492\n",
            "Epoch 328/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2565 - acc: 0.9536\n",
            "Epoch 329/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2543 - acc: 0.9470\n",
            "Epoch 330/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2530 - acc: 0.9492\n",
            "Epoch 331/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2521 - acc: 0.9514\n",
            "Epoch 332/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2495 - acc: 0.9448\n",
            "Epoch 333/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2479 - acc: 0.9514\n",
            "Epoch 334/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2464 - acc: 0.9470\n",
            "Epoch 335/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2450 - acc: 0.9448\n",
            "Epoch 336/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2435 - acc: 0.9448\n",
            "Epoch 337/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2421 - acc: 0.9448\n",
            "Epoch 338/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2422 - acc: 0.9448\n",
            "Epoch 339/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2398 - acc: 0.9470\n",
            "Epoch 340/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2374 - acc: 0.9514\n",
            "Epoch 341/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2364 - acc: 0.9448\n",
            "Epoch 342/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2345 - acc: 0.9470\n",
            "Epoch 343/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2328 - acc: 0.9448\n",
            "Epoch 344/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2310 - acc: 0.9492\n",
            "Epoch 345/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2297 - acc: 0.9514\n",
            "Epoch 346/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2294 - acc: 0.9514\n",
            "Epoch 347/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2279 - acc: 0.9448\n",
            "Epoch 348/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2260 - acc: 0.9470\n",
            "Epoch 349/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2253 - acc: 0.9492\n",
            "Epoch 350/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2271 - acc: 0.9448\n",
            "Epoch 351/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2223 - acc: 0.9470\n",
            "Epoch 352/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2217 - acc: 0.9492\n",
            "Epoch 353/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2198 - acc: 0.9514\n",
            "Epoch 354/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2196 - acc: 0.9492\n",
            "Epoch 355/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2207 - acc: 0.9492\n",
            "Epoch 356/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2204 - acc: 0.9492\n",
            "Epoch 357/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2206 - acc: 0.9492\n",
            "Epoch 358/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2331 - acc: 0.9470\n",
            "Epoch 359/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2255 - acc: 0.9448\n",
            "Epoch 360/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2232 - acc: 0.9426\n",
            "Epoch 361/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2256 - acc: 0.9492\n",
            "Epoch 362/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2200 - acc: 0.9492\n",
            "Epoch 363/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2139 - acc: 0.9514\n",
            "Epoch 364/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2114 - acc: 0.9514\n",
            "Epoch 365/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2076 - acc: 0.9492\n",
            "Epoch 366/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2070 - acc: 0.9492\n",
            "Epoch 367/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2051 - acc: 0.9514\n",
            "Epoch 368/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2040 - acc: 0.9492\n",
            "Epoch 369/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2031 - acc: 0.9492\n",
            "Epoch 370/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2024 - acc: 0.9448\n",
            "Epoch 371/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2024 - acc: 0.9492\n",
            "Epoch 372/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2014 - acc: 0.9470\n",
            "Epoch 373/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2027 - acc: 0.9514\n",
            "Epoch 374/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2015 - acc: 0.9470\n",
            "Epoch 375/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2110 - acc: 0.9470\n",
            "Epoch 376/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2073 - acc: 0.9470\n",
            "Epoch 377/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2077 - acc: 0.9426\n",
            "Epoch 378/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2016 - acc: 0.9492\n",
            "Epoch 379/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1985 - acc: 0.9514\n",
            "Epoch 380/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1961 - acc: 0.9514\n",
            "Epoch 381/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1938 - acc: 0.9492\n",
            "Epoch 382/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1927 - acc: 0.9514\n",
            "Epoch 383/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1915 - acc: 0.9492\n",
            "Epoch 384/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1900 - acc: 0.9514\n",
            "Epoch 385/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1906 - acc: 0.9536\n",
            "Epoch 386/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1901 - acc: 0.9448\n",
            "Epoch 387/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1909 - acc: 0.9536\n",
            "Epoch 388/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1886 - acc: 0.9492\n",
            "Epoch 389/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1942 - acc: 0.9492\n",
            "Epoch 390/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1962 - acc: 0.9426\n",
            "Epoch 391/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1964 - acc: 0.9492\n",
            "Epoch 392/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1861 - acc: 0.9514\n",
            "Epoch 393/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1849 - acc: 0.9514\n",
            "Epoch 394/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1829 - acc: 0.9536\n",
            "Epoch 395/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1815 - acc: 0.9492\n",
            "Epoch 396/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1805 - acc: 0.9492\n",
            "Epoch 397/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1796 - acc: 0.9492\n",
            "Epoch 398/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1789 - acc: 0.9470\n",
            "Epoch 399/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1776 - acc: 0.9470\n",
            "Epoch 400/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1772 - acc: 0.9492\n",
            "Epoch 401/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1754 - acc: 0.9536\n",
            "Epoch 402/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1754 - acc: 0.9470\n",
            "Epoch 403/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1746 - acc: 0.9514\n",
            "Epoch 404/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1751 - acc: 0.9492\n",
            "Epoch 405/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1737 - acc: 0.9492\n",
            "Epoch 406/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1730 - acc: 0.9536\n",
            "Epoch 407/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1723 - acc: 0.9470\n",
            "Epoch 408/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1713 - acc: 0.9514\n",
            "Epoch 409/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1720 - acc: 0.9470\n",
            "Epoch 410/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1702 - acc: 0.9514\n",
            "Epoch 411/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1690 - acc: 0.9470\n",
            "Epoch 412/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1688 - acc: 0.9492\n",
            "Epoch 413/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1689 - acc: 0.9492\n",
            "Epoch 414/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1690 - acc: 0.9470\n",
            "Epoch 415/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1696 - acc: 0.9514\n",
            "Epoch 416/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1670 - acc: 0.9492\n",
            "Epoch 417/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1651 - acc: 0.9514\n",
            "Epoch 418/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1667 - acc: 0.9470\n",
            "Epoch 419/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1665 - acc: 0.9492\n",
            "Epoch 420/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1633 - acc: 0.9470\n",
            "Epoch 421/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1627 - acc: 0.9448\n",
            "Epoch 422/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1618 - acc: 0.9470\n",
            "Epoch 423/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1611 - acc: 0.9470\n",
            "Epoch 424/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1610 - acc: 0.9492\n",
            "Epoch 425/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1594 - acc: 0.9536\n",
            "Epoch 426/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1592 - acc: 0.9536\n",
            "Epoch 427/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1584 - acc: 0.9492\n",
            "Epoch 428/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1576 - acc: 0.9470\n",
            "Epoch 429/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1573 - acc: 0.9470\n",
            "Epoch 430/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1579 - acc: 0.9470\n",
            "Epoch 431/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1562 - acc: 0.9514\n",
            "Epoch 432/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1564 - acc: 0.9492\n",
            "Epoch 433/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1559 - acc: 0.9470\n",
            "Epoch 434/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1555 - acc: 0.9492\n",
            "Epoch 435/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1556 - acc: 0.9470\n",
            "Epoch 436/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1541 - acc: 0.9448\n",
            "Epoch 437/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1532 - acc: 0.9536\n",
            "Epoch 438/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1523 - acc: 0.9448\n",
            "Epoch 439/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1520 - acc: 0.9492\n",
            "Epoch 440/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1515 - acc: 0.9470\n",
            "Epoch 441/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1510 - acc: 0.9470\n",
            "Epoch 442/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1511 - acc: 0.9470\n",
            "Epoch 443/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1502 - acc: 0.9514\n",
            "Epoch 444/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1492 - acc: 0.9492\n",
            "Epoch 445/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1485 - acc: 0.9404\n",
            "Epoch 446/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1482 - acc: 0.9470\n",
            "Epoch 447/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1477 - acc: 0.9514\n",
            "Epoch 448/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1471 - acc: 0.9470\n",
            "Epoch 449/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1461 - acc: 0.9470\n",
            "Epoch 450/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1466 - acc: 0.9492\n",
            "Epoch 451/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1469 - acc: 0.9448\n",
            "Epoch 452/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1461 - acc: 0.9492\n",
            "Epoch 453/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1451 - acc: 0.9492\n",
            "Epoch 454/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1445 - acc: 0.9492\n",
            "Epoch 455/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1437 - acc: 0.9492\n",
            "Epoch 456/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1449 - acc: 0.9492\n",
            "Epoch 457/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1440 - acc: 0.9470\n",
            "Epoch 458/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1436 - acc: 0.9492\n",
            "Epoch 459/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1422 - acc: 0.9492\n",
            "Epoch 460/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1423 - acc: 0.9426\n",
            "Epoch 461/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1413 - acc: 0.9492\n",
            "Epoch 462/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1407 - acc: 0.9492\n",
            "Epoch 463/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1426 - acc: 0.9492\n",
            "Epoch 464/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1446 - acc: 0.9492\n",
            "Epoch 465/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1426 - acc: 0.9514\n",
            "Epoch 466/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1402 - acc: 0.9536\n",
            "Epoch 467/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1398 - acc: 0.9470\n",
            "Epoch 468/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1395 - acc: 0.9470\n",
            "Epoch 469/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1428 - acc: 0.9404\n",
            "Epoch 470/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1396 - acc: 0.9448\n",
            "Epoch 471/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1417 - acc: 0.9360\n",
            "Epoch 472/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1394 - acc: 0.9448\n",
            "Epoch 473/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1394 - acc: 0.9514\n",
            "Epoch 474/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1448 - acc: 0.9514\n",
            "Epoch 475/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1518 - acc: 0.9514\n",
            "Epoch 476/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1622 - acc: 0.9448\n",
            "Epoch 477/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1668 - acc: 0.9470\n",
            "Epoch 478/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2007 - acc: 0.9382\n",
            "Epoch 479/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2404 - acc: 0.9272\n",
            "Epoch 480/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2466 - acc: 0.9205\n",
            "Epoch 481/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2323 - acc: 0.9294\n",
            "Epoch 482/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.2259 - acc: 0.9338\n",
            "Epoch 483/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1940 - acc: 0.9338\n",
            "Epoch 484/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1858 - acc: 0.9470\n",
            "Epoch 485/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1998 - acc: 0.9382\n",
            "Epoch 486/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1722 - acc: 0.9426\n",
            "Epoch 487/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1602 - acc: 0.9470\n",
            "Epoch 488/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1676 - acc: 0.9360\n",
            "Epoch 489/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1564 - acc: 0.9448\n",
            "Epoch 490/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1459 - acc: 0.9470\n",
            "Epoch 491/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1467 - acc: 0.9492\n",
            "Epoch 492/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1408 - acc: 0.9426\n",
            "Epoch 493/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1390 - acc: 0.9426\n",
            "Epoch 494/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1364 - acc: 0.9470\n",
            "Epoch 495/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1374 - acc: 0.9470\n",
            "Epoch 496/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1356 - acc: 0.9492\n",
            "Epoch 497/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1349 - acc: 0.9470\n",
            "Epoch 498/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1345 - acc: 0.9492\n",
            "Epoch 499/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1338 - acc: 0.9492\n",
            "Epoch 500/500\n",
            "453/453 [==============================] - 1s 1ms/sample - loss: 0.1338 - acc: 0.9448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YXGelKThoTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poeprYK8h-c7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "ffd7c926-34f4-44aa-e053-ab7281d64ecc"
      },
      "source": [
        "plot_graphs(history, 'acc')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/pvV48ye8AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "67831894-1b49-412d-e706-47587f55aa73"
      },
      "source": [
        "seed_text = \"Laurence went to dublin\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Laurence went to dublin that end for to friends relations relations relations didnt come all all all wall wall jig a cask cask jig call might hall eyes glisten glisten glisten glisten had up a eyes glisten glisten glisten glisten had up saw ground saw saw boys three up saw saw saw saw come come all all i wall invitation might hullabaloo table painted painted might ask eyes glisten glisten glisten glisten had up saw saw saw might hall eyes glisten glisten glisten able had up saw ground saw saw boys three up saw saw saw saw come come all all i wall invitation\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}